{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Comet and LangChain to track LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install comet_ml\n",
    "!pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import comet_ml\n",
    "import openai\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "from langchain.callbacks import CometCallbackHandler, StdOutCallbackHandler\n",
    "from langchain.callbacks.base import BaseCallbackManager\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")\n",
    "os.environ[\"COMET_API_KEY\"] = os.getenv(\"COMET_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: openai.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/omarsar/llm/b2539e88cee54fb5a2690b271f2dbd20\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : langchain\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (3.62 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: openai.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/omarsar/llm/7d0cc0d771f1428a9dfafe177ad1e983\n",
      "\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m The comet_ml callback is currently in beta and is subject to change based on updates to `langchain`. Please report any issues to https://github.com/comet-ml/issue-tracking/issues with the tag `langchain`.\n"
     ]
    }
   ],
   "source": [
    "# define comet callback\n",
    "comet_callback = CometCallbackHandler(\n",
    "    project_name=\"llm\",\n",
    "    complexity_metrics=True,\n",
    "    stream_logs=True,\n",
    "    tags=[\"agent\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "manager = BaseCallbackManager([StdOutCallbackHandler(), comet_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unexpected data format provided! Input Value for stop will not be logged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\n",
      "Thought:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unexpected data format provided! Input Value for stop will not be logged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out both pieces of information\n",
      "Action: Search\n",
      "Action Input: Leo DiCaprio's girlfriend\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mDiCaprio broke up with girlfriend Camila Morrone, 25, in the summer of 2022, after dating for four years. He's since been linked to another famous supermodel – Gigi Hadid. The power couple were first supposedly an item in September after being spotted getting cozy during a party at New York Fashion Week.\u001b[0m\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\n",
      "Thought: I need to find out both pieces of information\n",
      "Action: Search\n",
      "Action Input: Leo DiCaprio's girlfriend\n",
      "Observation: DiCaprio broke up with girlfriend Camila Morrone, 25, in the summer of 2022, after dating for four years. He's since been linked to another famous supermodel – Gigi Hadid. The power couple were first supposedly an item in September after being spotted getting cozy during a party at New York Fashion Week.\n",
      "Thought:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to use the calculator to work out her age raised to the 0.43 power\n",
      "Action: Calculator\n",
      "Action Input: 25^0.43\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Unexpected data format provided! Input Value for stop will not be logged\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 3.991298452658078\u001b[0m\n",
      "Thought:\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnswer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search: A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search, Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\n",
      "Thought: I need to find out both pieces of information\n",
      "Action: Search\n",
      "Action Input: Leo DiCaprio's girlfriend\n",
      "Observation: DiCaprio broke up with girlfriend Camila Morrone, 25, in the summer of 2022, after dating for four years. He's since been linked to another famous supermodel – Gigi Hadid. The power couple were first supposedly an item in September after being spotted getting cozy during a party at New York Fashion Week.\n",
      "Thought: I need to use the calculator to work out her age raised to the 0.43 power\n",
      "Action: Calculator\n",
      "Action Input: 25^0.43\n",
      "Observation: Answer: 3.991298452658078\n",
      "Thought:\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;196mCOMET ERROR:\u001b[0m Failed to export agent or LLM to Comet\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/callbacks/comet_ml_callback.py\", line 484, in _log_model\n",
      "    langchain_asset.save(langchain_asset_path)\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/agents/agent.py\", line 656, in save\n",
      "    raise ValueError(\n",
      "ValueError: Saving not supported for agent executors. If you are trying to save the agent, please use the `.save_agent(...)`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/callbacks/comet_ml_callback.py\", line 449, in flush_tracker\n",
      "    self._log_model(langchain_asset)\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/callbacks/comet_ml_callback.py\", line 488, in _log_model\n",
      "    langchain_asset.save_agent(langchain_asset_path)\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/agents/agent.py\", line 664, in save_agent\n",
      "    return self.agent.save(file_path)\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/agents/agent.py\", line 160, in save\n",
      "    agent_dict = self.dict()\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/agents/agent.py\", line 134, in dict\n",
      "    _dict = super().dict()\n",
      "  File \"pydantic/main.py\", line 449, in pydantic.main.BaseModel.dict\n",
      "  File \"pydantic/main.py\", line 868, in _iter\n",
      "  File \"pydantic/main.py\", line 743, in pydantic.main.BaseModel._get_value\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/schema.py\", line 356, in dict\n",
      "    output_parser_dict[\"_type\"] = self._type\n",
      "  File \"/Users/elvissaravia/opt/miniconda3/envs/langchain/lib/python3.9/site-packages/langchain/schema.py\", line 351, in _type\n",
      "    raise NotImplementedError\n",
      "NotImplementedError\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/omarsar/llm/7d0cc0d771f1428a9dfafe177ad1e983\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_25% [4]   : (4.9, 30.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_50% [4]   : (4.9, 30.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_75% [4]   : (4.9, 30.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_count     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_max [4]   : (4.9, 30.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_mean [4]  : (4.9, 30.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_min [4]   : (4.9, 30.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     automated_readability_index_std       : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_25% [4]            : (5.83, 12.18)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_50% [4]            : (5.83, 12.18)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_75% [4]            : (5.83, 12.18)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_count              : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_max [4]            : (5.83, 12.18)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_mean [4]           : (5.83, 12.18)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_min [4]            : (5.83, 12.18)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     coleman_liau_index_std                : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_25% [4]                      : (1.2, 2.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_50% [4]                      : (1.2, 2.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_75% [4]                      : (1.2, 2.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_count                        : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_max [4]                      : (1.2, 2.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_mean [4]                     : (1.2, 2.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_min [4]                      : (1.2, 2.7)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     crawford_std                          : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_25% [4]  : (9.42, 22.83)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_50% [4]  : (9.42, 22.83)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_75% [4]  : (9.42, 22.83)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_count    : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_max [4]  : (9.42, 22.83)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_mean [4] : (9.42, 22.83)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_min [4]  : (9.42, 22.83)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dale_chall_readability_score_std      : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_25% [4]               : (2.0, 6.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_50% [4]               : (2.0, 6.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_75% [4]               : (2.0, 6.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_count                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_max [4]               : (2.0, 6.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_mean [4]              : (2.0, 6.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_min [4]               : (2.0, 6.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     difficult_words_std                   : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_25% [4]              : (81.74, 113.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_50% [4]              : (81.74, 113.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_75% [4]              : (81.74, 113.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_count                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_max [4]              : (81.74, 113.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_mean [4]             : (81.74, 113.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_min [4]              : (81.74, 113.35)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     fernandez_huerta_std                  : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_25% [4]          : (4.6, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_50% [4]          : (4.6, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_75% [4]          : (4.6, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_count            : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_max [4]          : (4.6, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_mean [4]         : (4.6, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_min [4]          : (4.6, 10.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_kincaid_grade_std              : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_25% [4]           : (32.56, 78.96)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_50% [4]           : (32.56, 78.96)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_75% [4]           : (32.56, 78.96)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_count             : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_max [4]           : (32.56, 78.96)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_mean [4]          : (32.56, 78.96)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_min [4]           : (32.56, 78.96)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     flesch_reading_ease_std               : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_25% [4]                : (45.0, 72.8)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_50% [4]                : (45.0, 72.8)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_75% [4]                : (45.0, 72.8)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_count                  : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_max [4]                : (45.0, 72.8)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_mean [4]               : (45.0, 72.8)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_min [4]                : (45.0, 72.8)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gulpease_index_std                    : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_25% [4]                   : (3.72, 18.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_50% [4]                   : (3.72, 18.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_75% [4]                   : (3.72, 18.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Camila Morrone, 25, is the current girlfriend of Leo DiCaprio. Her current age raised to the 0.43 power is 3.991298452658078.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_count                     : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_max [4]                   : (3.72, 18.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_mean [4]                  : (3.72, 18.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_min [4]                   : (3.72, 18.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gunning_fog_std                       : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_25% [4]              : (37.19, 50.42)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_50% [4]              : (37.19, 50.42)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_75% [4]              : (37.19, 50.42)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_count                : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_max [4]              : (37.19, 50.42)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_mean [4]             : (37.19, 50.42)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_min [4]              : (37.19, 50.42)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     gutierrez_polini_std                  : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_25% [4]         : (3.666666666666667, 8.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_50% [4]         : (3.666666666666667, 8.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_75% [4]         : (3.666666666666667, 8.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_count           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_max [4]         : (3.666666666666667, 8.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_mean [4]        : (3.666666666666667, 8.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_min [4]         : (3.666666666666667, 8.0)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     linsear_write_formula_std             : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_25% [4]                         : (11.94, 80.74)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_50% [4]                         : (11.94, 80.74)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_75% [4]                         : (11.94, 80.74)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_count                           : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_max [4]                         : (11.94, 80.74)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_mean [4]                        : (11.94, 80.74)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_min [4]                         : (11.94, 80.74)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     osman_std                             : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_25% [4]                    : (0.0, 3.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_50% [4]                    : (0.0, 3.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_75% [4]                    : (0.0, 3.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_count                      : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_max [4]                    : (0.0, 3.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_mean [4]                   : (0.0, 3.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_min [4]                    : (0.0, 3.1)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     smog_index_std                        : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_25% [4]               : (77.24, 110.73)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_50% [4]               : (77.24, 110.73)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_75% [4]               : (77.24, 110.73)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_count                 : 1.0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_max [4]               : (77.24, 110.73)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_mean [4]              : (77.24, 110.73)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_min [4]               : (77.24, 110.73)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     szigriszt_pazos_std                   : nan\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     Created from : langchain\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model__type             : openai\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_frequency_penalty : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_logit_bias        : {}\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_max_tokens        : 256\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_model_name        : text-davinci-003\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_n                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_presence_penalty  : 0\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_request_timeout   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_temperature       : 0.9\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model_top_p             : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     asset                        : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     dataframe                    : 1 (6.17 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (3.62 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     text-sample                  : 29\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: openai.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(temperature=0.9, callback_manager=manager, verbose=True)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callback_manager=manager)\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=\"zero-shot-react-description\",\n",
    "    callback_manager=manager,\n",
    "    verbose=True,\n",
    ")\n",
    "agent.run(\n",
    "    \"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\"\n",
    ")\n",
    "comet_callback.flush_tracker(agent, finish=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
