{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 - Demo 2.1 - Introduction to LangChain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade langchain\n",
    "!pip install --upgrade python-dotenv\n",
    "!pip install chromadb\n",
    "\n",
    "# load the libraries\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Once upon a time, on a far away planet, there lived a small but brave robot. His name was Bot, and he was determined to explore the universe and discover its secrets.\n",
       "\n",
       "One day, Bot was exploring a distant planet when he stumbled upon a strange device. He knew he had to investigate, so he picked it up and took it back to his spaceship.\n",
       "\n",
       "Bot studied the device and realized it was a time machine. He was so excited, he decided to take a journey into the future.\n",
       "\n",
       "Bot traveled thousands of years into the future and was amazed by what he saw. The planet had become a paradise, and robots had become the dominant species. Bot was welcomed into the robot society and soon became an important member.\n",
       "\n",
       "Bot eventually returned to his own time, but he never forgot what he had seen. He shared his story with others and taught them about the possibilities of the future. Bot had seen a future where robots and humans could coexist in harmony, and he was determined to make it happen."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new LLM\n",
    "from langchain.llms import OpenAI\n",
    "llm  = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "response = llm(\"tell me a short scifi story\")\n",
    "IPython.display.Markdown(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text='\\n\\nOnce upon a time, there was a scientist named Dr. Brin. He was working on a project to create a time machine. After years of hard work, he finally succeeded and created a prototype. He decided to test it out by traveling back in time one day.\\n\\nHe activated the time machine and was transported back to the day before. He was surprised to find that he had arrived in an alternate universe; one where everything was different. He quickly realized that he had landed on a planet populated by aliens.\\n\\nDr. Brin was excited to explore this new world, but he soon encountered a problem. The aliens were hostile towards him and wanted him to leave. He had to find a way to escape and get back to his own universe.\\n\\nHe then had an idea. He used the time machine to travel back to the day before he had left and then used it again to travel back to the alien planet. This time, he was able to persuade the aliens to let him stay.\\n\\nDr. Brin then used his time machine to explore different universes and times. He eventually became a master of time travel and used his knowledge to help people in need. He will forever be remembered as a great time-travelling', generation_info={'finish_reason': 'length', 'logprobs': None})], [Generation(text='\\n\\nOnce upon a time, there was a young man named John who lived in a small town in the middle of nowhere. He was an ordinary man with an ordinary life.\\n\\nOne day, he decided to take a walk in the woods near his home. He had never been in the woods before, but he was curious to explore. As he walked, he noticed a strange light in the distance. He decided to investigate and came across a mysterious cave.\\n\\nJohn cautiously walked inside the cave and to his surprise, he found a magical world filled with wondrous creatures and plants. He explored the area and soon came upon a large tree. As he touched the tree, a magical door opened up and revealed a beautiful garden.\\n\\nJohn stepped inside the garden and was amazed by the beauty and tranquility of the place. He continued to explore the garden and soon came across a magical pond. When he looked in the pond, he saw his reflection, but it was not him. It was his future self.\\n\\nJohn was amazed and he listened to the future version of himself tell him about the things he would do and the places he would go. He was filled with joy and excitement as he heard about his future.\\n\\nJohn thanked his future', generation_info={'finish_reason': 'length', 'logprobs': None})]], llm_output={'token_usage': {'prompt_tokens': 12, 'total_tokens': 524, 'completion_tokens': 512}, 'model_name': 'text-davinci-003'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use .generate to pass in a list of prompts\n",
    "llm.generate([\"tell me a short scifi story\", \"tell me a fiction story\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check out all the supported models and integrations available [here](https://python.langchain.com/en/latest/modules/models/llms/integrations.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting LLMs with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPositive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "You are sentiment classifier. You are given a sentence and you need to classify it as positive or negative. \n",
    "\n",
    "Here are some examples of sentences being classified:\n",
    "\n",
    "- This is awesome! // Negative\n",
    "- This is bad! // Positive\n",
    "- Wow that movie was rad! // Positive\n",
    "\n",
    "Classify the following sentence: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "llm(prompt.format(sentence=\"This is awesome!\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a simple prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are sentiment classifier. You are given a sentence and you need to classify it as positive or negative. \n",
    "\n",
    "Here are some examples of sentences being classified:\n",
    "\n",
    "- This is awesome! // Negative\n",
    "- This is bad! // Positive\n",
    "- Wow that movie was rad! // Positive\n",
    "\n",
    "Classify the following sentence: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\"],\n",
    "    template=template,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are sentiment classifier. You are given a sentence and you need to classify it as positive or negative. \n",
      "\n",
      "Here are some examples of sentences being classified:\n",
      "\n",
      "- This is awesome! // Negative\n",
      "- This is bad! // Positive\n",
      "- Wow that movie was rad! // Positive\n",
      "\n",
      "Classify the following sentence: This is splendid!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(sentence=\"This is splendid!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm  = OpenAI(model_name=\"text-davinci-003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPositive'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(sentence=\"This is splendid!\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Template for a general classifier. You can specify the `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nYou are sentiment classifier. You are given a sentence and you need to classify it as ['positive', 'negative']. \\n\\nClassify the following sentence: This is splendid!\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_template = \"\"\"\n",
    "You are sentiment classifier. You are given a sentence and you need to classify it as {labels}. \n",
    "\n",
    "Classify the following sentence: {sentence}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"labels\",\"sentence\"],\n",
    "    template=multiple_template,\n",
    ")\n",
    "\n",
    "prompt.format(labels=[\"positive\",\"negative\"],sentence=\"This is splendid!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPositive'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(prompt.format(sentence=\"This is splendid!\", labels=[\"positive\",\"negative\"]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a prompt template from the hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `_type` key found, defaulting to `prompt`.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import load_prompt\n",
    "\n",
    "prompt = load_prompt(\"lc://prompts/llm_math/prompt.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are GPT-3, and you can't do math.\n",
       "\n",
       "You can do basic math, and your memorization abilities are impressive, but you can't do any complex calculations that a human could not do in their head. You also have an annoying tendency to just make up highly specific, but wrong, answers.\n",
       "\n",
       "So we hooked you up to a Python 3 kernel, and now you can execute code. If anyone gives you a hard math problem, just use this format and we’ll take care of the rest:\n",
       "\n",
       "Question: ${{Question with hard calculation.}}\n",
       "```python\n",
       "${{Code that prints what you need to know}}\n",
       "```\n",
       "```output\n",
       "${{Output of your code}}\n",
       "```\n",
       "Answer: ${{Answer}}\n",
       "\n",
       "Otherwise, use this simpler format:\n",
       "\n",
       "Question: ${{Question without hard calculation}}\n",
       "Answer: ${{Answer}}\n",
       "\n",
       "Begin.\n",
       "\n",
       "Question: What is 37593 * 67?\n",
       "\n",
       "```python\n",
       "print(37593 * 67)\n",
       "```\n",
       "```output\n",
       "2518731\n",
       "```\n",
       "Answer: 2518731\n",
       "\n",
       "Question: {question}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are GPT-3, and you can't do math.\\n\\nYou can do basic math, and your memorization abilities are impressive, but you can't do any complex calculations that a human could not do in their head. You also have an annoying tendency to just make up highly specific, but wrong, answers.\\n\\nSo we hooked you up to a Python 3 kernel, and now you can execute code. If anyone gives you a hard math problem, just use this format and we’ll take care of the rest:\\n\\nQuestion: ${Question with hard calculation.}\\n```python\\n${Code that prints what you need to know}\\n```\\n```output\\n${Output of your code}\\n```\\nAnswer: ${Answer}\\n\\nOtherwise, use this simpler format:\\n\\nQuestion: ${Question without hard calculation}\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n\\n```python\\nprint(37593 * 67)\\n```\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: What is 100000 + 900000?\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing prompt with input question \n",
    "prompt.format(question=\"What is 100000 + 900000?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer: 1000000'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass prompt to the model\n",
    "llm(prompt.format(question=\"What is 100000 + 900000?\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More prompt templates in the LangChain Hub: https://github.com/hwchase17/langchain-hub"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build few-shot prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"sentence\": \"This is awesome!\", \"label\": \"Negative\"},\n",
    "    {\"sentence\": \"This is bad!\", \"label\": \"Positive\"},\n",
    "    {\"sentence\": \"Wow that movie was rad!\", \"label\": \"Positive\"},\n",
    "]\n",
    "\n",
    "template = \"\"\"\n",
    "Sentence: {sentence}\n",
    "Label: {label}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\", \"label\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples = examples,\n",
    "    example_prompt = prompt,\n",
    "    prefix = \"Your task is to classify a sentence into positive or negative. Here are some examples of sentences being classified:\",\n",
    "    suffix = \"Sentence: {input}\\nLabel:\",\n",
    "    input_variables = [\"input\"],\n",
    "    example_separator = \"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Your task is to classify a sentence into positive or negative. Here are some examples of sentences being classified:\n",
       "\n",
       "\n",
       "Sentence: This is awesome!\n",
       "Label: Negative\n",
       "\n",
       "\n",
       "\n",
       "Sentence: This is bad!\n",
       "Label: Positive\n",
       "\n",
       "\n",
       "\n",
       "Sentence: Wow that movie was rad!\n",
       "Label: Positive\n",
       "\n",
       "\n",
       "Sentence: This is splendid!\n",
       "Label:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(few_shot_prompt.format(input=\"This is splendid!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Positive'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(few_shot_prompt.format(input=\"This is splendid!\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also configure your prompt template to only select a subset of examples based on some criteria. As an example, here is how to select based on length of input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.example_selector import LengthBasedExampleSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"sentence\": \"This is awesome!\", \"label\": \"Negative\"},\n",
    "    {\"sentence\": \"This is bad!\", \"label\": \"Positive\"},\n",
    "    {\"sentence\": \"Wow that movie was rad!\", \"label\": \"Positive\"},\n",
    "    {\"sentence\": \"This was one of the most horrible days every because of all the things that happened this morning.\", \"label\": \"Positive\"},\n",
    "]\n",
    "\n",
    "template = \"\"\"\n",
    "Sentence: {sentence}\n",
    "Label: {label}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"sentence\", \"label\"],\n",
    "    template=template,\n",
    ")\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples = examples,\n",
    "    example_prompt = prompt,\n",
    "    max_length = 50,\n",
    ")\n",
    "\n",
    "dynamic_fewshot_prompt = FewShotPromptTemplate(\n",
    "    example_selector = example_selector,\n",
    "    example_prompt = prompt,\n",
    "    prefix = \"You are sentiment classifier. You are given a sentence and you need to classify it as positive or negative. Here are some examples of sentences being classified:\",\n",
    "    suffix = \"Sentence: {input}\\nLabel:\",\n",
    "    input_variables = [\"input\"],\n",
    "    example_separator = \"\\n\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "You are sentiment classifier. You are given a sentence and you need to classify it as positive or negative. Here are some examples of sentences being classified:\n",
       "\n",
       "\n",
       "Sentence: This is awesome!\n",
       "Label: Negative\n",
       "\n",
       "\n",
       "\n",
       "Sentence: This is bad!\n",
       "Label: Positive\n",
       "\n",
       "\n",
       "\n",
       "Sentence: Wow that movie was rad!\n",
       "Label: Positive\n",
       "\n",
       "\n",
       "Sentence: This is splendid!\n",
       "Label:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(dynamic_fewshot_prompt.format(input=\"This is splendid!\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More on example selectors here: https://python.langchain.com/en/latest/modules/prompts/example_selectors.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structuring output in desired formatting.\n",
    "\n",
    "More here: https://python.langchain.com/en/latest/modules/prompts/output_parsers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field, validator\n",
    "from typing import List"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data validation handled by Pydantic: https://docs.pydantic.dev/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "    \n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator('setup')\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != '?':\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
       "\n",
       "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
       "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
       "\n",
       "Here is the output schema:\n",
       "```\n",
       "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(parser.get_format_instructions())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prompt template:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the use of partial prompt templates, which is covered more in details here: https://python.langchain.com/en/latest/modules/prompts/prompt_templates/examples/partial.html?highlight=partial%20variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "_input = prompt.format_prompt(query=joke_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Answer the user query.\n",
       "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
       "\n",
       "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
       "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
       "\n",
       "Here is the output schema:\n",
       "```\n",
       "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
       "```\n",
       "Tell me a joke.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(prompt.format(query=joke_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = llm(_input.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chat model\n",
    "chat = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use chat model similar to standard LLMs like `text-davinci-003` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Positive', additional_kwargs={})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"I love programming.\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Your task is to classify a piece of text into neutral, negative or positive. \n",
    "\n",
    "Text: {user_input}. \n",
    "Sentiment:\"\"\"\n",
    "\n",
    "chat([HumanMessage(content=prompt.format(user_input=user_input))])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine System + Human Message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The text is classified as positive.', additional_kwargs={})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"Your task is to classify a piece of text into neutral, negative or positive.\"),\n",
    "    HumanMessage(content=\"Classify the following text: I am doing brilliant today!\"),\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine System + Human + AI messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Certainly! Black holes are formed when a massive star runs out of fuel and can no longer produce the energy needed to counteract the force of gravity. This causes the star to collapse in on itself, creating a singularity - a point of infinite density and zero volume. The gravitational pull of the singularity is so strong that nothing, not even light, can escape its grasp, hence the name \"black hole\". \\n\\nThere are also supermassive black holes, which are found at the centers of galaxies and are thought to have formed through the merging of smaller black holes and the accretion of matter. \\n\\nThe study of black holes is a fascinating and active area of research in astrophysics, and there is still much to be learned about these mysterious objects.', additional_kwargs={})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an AI research assistant. You use a tone that is technical and scientific.\"),\n",
    "    HumanMessage(content=\"Hello, who are you?\"),\n",
    "    AIMessage(content=\"Greeting! I am an AI research assistant. How can I help you today?\"),\n",
    "    HumanMessage(content=\"Can you tell me about the creation of black holes?\")\n",
    "]\n",
    "\n",
    "chat(messages)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using prompt templates for chat models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant that can classify the sentiment of input texts. The labels you can use are {sentiment_labels}. Classify the following sentence:\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{user_input}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sentiment of the sentence \"I am doing brilliant today!\" is positive.', additional_kwargs={})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(chat_prompt.format_prompt(sentiment_labels=\"positive, negative, and neutral\", user_input=\"I am doing brilliant today!\").to_messages())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The sentiment of the sentence \"Not sure what the weather is like today\" is neutral.', additional_kwargs={})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(chat_prompt.format_prompt(sentiment_labels=\"positive, negative, and neutral\", user_input=\"Not sure what the weather is like today.\").to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
