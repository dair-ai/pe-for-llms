{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2 - Demo 2.2 - Model Reliability & Enhancing LLMs\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/dair-ai/pe-for-llms/blob/main/notebooks/session-2/demo-2.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade langchain\n",
    "!pip install --upgrade python-dotenv\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using `text-davinci-003` for all examples in this tutorial. You can easily switch to `gpt-3.5-turbo`, however, note that this model is more expensive and slower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm instance\n",
    "llm_text_davinci = OpenAI(model_name='text-davinci-003', temperature=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting token usage\n",
    "\n",
    "We will use `tiktoken`, an open-source tokenizer by OpenAI.\n",
    "\n",
    "https://github.com/openai/tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load encoding by name\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# load the correct encoding by passing the model name\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 1097, 8430, 6380, 3432]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize text\n",
    "encoding.encode(\"I am feeling happy today\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count tokens\n",
    "len(encoding.encode(\"I am feeling happy today\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gpt-4 model\n",
    "gpt4_encoding = tiktoken.encoding_for_model(\"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 1097, 8430, 6380, 3432]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4_encoding.encode(\"I am feeling happy today\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also calculate token usage with LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks import get_openai_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 190\n",
      "\tPrompt Tokens: 8\n",
      "\tCompletion Tokens: 182\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.0038\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "\n",
    "# anything inside the context manager will be tracked\n",
    "with get_openai_callback() as cb:\n",
    "    result = llm(\"Tell me a short story about a robot\")\n",
    "    print(cb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Be clear and specific when prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, couldn't find a movie to recommend today.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_trending_movies = [\"The Suicide Squad\", \"No Time to Die\", \"Dune\",  \"Spider-Man: No Way Home\", \"The French Dispatch\", \"Black Widow\", \"Eternals\", \"The Matrix Resurrections\", \"West Side Story\", \"The Many Saints of Newark\"]\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "Your task is to recommend movies to a customer. \n",
    "\n",
    "You are responsible to recommend a movie from the top global trending movies from {global_trending_movies}. \n",
    "\n",
    "You should refrain from asking users for their preferences and avoid asking for personal information.\n",
    "\n",
    "If you don't have a movie to recommend, you should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
    "\n",
    "Customer: Please recommend a movie based on my interests.\n",
    "Agent: \n",
    "\"\"\"\n",
    "\n",
    "llm_text_davinci(prompt.format(global_trending_movies=global_trending_movies))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example where the customer provides information about interests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I recommend Spider-Man: No Way Home. It's a highly anticipated sequel to the Marvel Cinematic Universe and is sure to be a hit with fans of super-hero movies.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_trending_movies = [\"The Suicide Squad\", \"No Time to Die\", \"Dune\",  \"Spider-Man: No Way Home\", \"The French Dispatch\", \"Black Widow\", \"Eternals\", \"The Matrix Resurrections\", \"West Side Story\", \"The Many Saints of Newark\"]\n",
    "\n",
    "\n",
    "prompt = \"\"\"\n",
    "Your task is to recommends movies to a customer. \n",
    "\n",
    "You are responsible to recommend a movie from the top global trending movies from {global_trending_movies}. \n",
    "\n",
    "You should refrain from asking users for their preferences and avoid asking for personal information.\n",
    "\n",
    "If you don't have a movie to recommend, you should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
    "\n",
    "Customer: I love super-hero movies. Please recommend a movie based on my interests.\n",
    "Agent: \n",
    "\"\"\"\n",
    "\n",
    "llm_text_davinci(prompt.format(global_trending_movies=global_trending_movies))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Delimiters to Distinguish Components of a Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Convert the following code block in the ### <code> ### section to Python:\n",
    "\n",
    "###\n",
    "strings2 = Array[]\n",
    "strings2.push(\"one\")\n",
    "strings2.push(\"two\")\n",
    "strings2.push(\"THREE\")\n",
    "###\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "strings2 = []\n",
       "strings2.append(\"one\")\n",
       "strings2.append(\"two\")\n",
       "strings2.append(\"THREE\")\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Markdown(\"```python\" + llm_text_davinci(prompt) + \"\\n```\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Output Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "{\n",
       "  \"product_name\": \"Nike Air Max 270 React\",\n",
       "  \"product_brand\": \"Nike\"\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Your task is: given a product description, return the requested information in the section delimited by ### ###. Format the output as a JSON object.\n",
    "\n",
    "Product Description: Introducing the Nike Air Max 270 React: a comfortable and stylish sneaker that combines two of Nike's best technologies. With a sleek black design and a unique bubble sole, these shoes are perfect for everyday wear.\n",
    "\n",
    "###\n",
    "product_name: the name of the product\n",
    "product_bran: the name of the brand (if any) \n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "IPython.display.Markdown(llm_text_davinci(prompt))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the Length of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We apologize for the inconvenience caused by the shipping issue with your recent order. We have located your package and it is on its way to you. We have taken steps to prevent similar issues from occurring in the future. Thank you for your understanding.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Your task is: given a customer support email, which is delimited with ###, generate a shorter 1-2 sentence response.\n",
    "\n",
    "###\n",
    "Dear [Customer],\n",
    "\n",
    "We hope this email finds you well. We wanted to update you on the shipping issue you experienced with your recent order. After investigating the issue, we have located your package and it is currently on its way to you. We apologize for any inconvenience this may have caused and thank you for your patience and understanding while we resolved this matter.\n",
    "\n",
    "Please note that we have taken steps to prevent similar issues from occurring in the future. We have improved our shipping tracking system and are now better equipped to ensure that packages arrive on time and in good condition. We take the quality of our service very seriously and want to ensure that all of our customers have a positive experience when shopping with us.\n",
    "\n",
    "Once again, we apologize for any inconvenience this may have caused and hope that you will continue to shop with us in the future. If you have any further questions or concerns, please do not hesitate to contact us. We are always here to help and ensure that your shopping experience is a positive one.\n",
    "\n",
    "Thank you for your understanding.\n",
    "\n",
    "Best regards,\n",
    "\n",
    "[Your Name]\n",
    "\n",
    "Customer Support Team\n",
    "###\n",
    "\"\"\"\n",
    "\n",
    "llm_text_davinci(prompt)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avoid deviating and constraining the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it helps to be more specific about what output you expect to avoid the model deviating from the main task of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nThe Grand Budapest Hotel (2014). This Wes Anderson classic is a delightful comedy-drama set in a European hotel in the 1930s. It follows the adventures of the hotel's concierge, Gustave H, and his loyal lobby boy, Zero Moustafa, as they try to solve a mystery involving a priceless painting. With an all-star cast, including Ralph Fiennes, Adrien Brody, and Willem Dafoe, this is a must-see for any movie fan.\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_text_davinci(\"Recommend a movie for Saturday:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe Princess Bride'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_text_davinci(\"Recommend a movie for Saturday. Just say the movie, no need for explanations!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
