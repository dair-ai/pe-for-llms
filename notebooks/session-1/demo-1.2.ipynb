{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 - Demo 1.2 - Advanced Prompting Techniques\n",
    "\n",
    "by Elvis Saravia\n",
    "\n",
    "We will be using the [OpenAI APIs](https://platform.openai.com/) for all examples. I am using the `text-davinci-003` model and the default settings `temperature=0.7` and `top-p=1`.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/dair-ai/pe-for-llms/blob/main/notebooks/session-1/demo-1.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade langchain\n",
    "!pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# for LangChain\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_open_params(\n",
    "    model=\"text-davinci-003\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "):\n",
    "    \"\"\" set openai parameters\"\"\"\n",
    "\n",
    "    openai_params = {}    \n",
    "\n",
    "    openai_params['model'] = model\n",
    "    openai_params['temperature'] = temperature\n",
    "    openai_params['max_tokens'] = max_tokens\n",
    "    openai_params['top_p'] = top_p\n",
    "    openai_params['frequency_penalty'] = frequency_penalty\n",
    "    openai_params['presence_penalty'] = presence_penalty\n",
    "    return openai_params\n",
    "\n",
    "def get_completion(params, prompt):\n",
    "    \"\"\" GET completion from openai api\"\"\"\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "        engine = params['model'],\n",
    "        prompt = prompt,\n",
    "        temperature = params['temperature'],\n",
    "        max_tokens = params['max_tokens'],\n",
    "        top_p = params['top_p'],\n",
    "        frequency_penalty = params['frequency_penalty'],\n",
    "        presence_penalty = params['presence_penalty'],\n",
    "    )\n",
    "    return response\n",
    "\n",
    "params = set_open_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few-shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The children were so excited that they began to farduddle around the playground."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"A \"whatpu\" is a small, furry animal native to Tanzania. \n",
    "An example of a sentence that uses the word whatpu is: We were traveling in Africa and we saw these very cute whatpus.\n",
    "\n",
    "To do a \"farduddle\" means to jump up and down really fast. \n",
    "An example of a sentence that uses the word farduddle is:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain-of-Thought (CoT) Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Adding all the odd numbers (15, 5, 13, 7, 1) gives 41. The answer is False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
    "\n",
    "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1. \n",
    "A:\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-Shot CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Initially, I had 10 apples.\n",
       "I gave 2 apples to the neighbor and 2 to the repairman. That's a total of 4 apples.\n",
       "\n",
       "So now I have 6 apples.\n",
       "\n",
       "I then bought 5 more apples and ate 1. That's a total of 6 apples.\n",
       "\n",
       "So now I have 12 apples.\n",
       "\n",
       "Therefore, I remain with 12 apples."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"I went to the market and bought 10 apples. I gave 2 apples to the neighbor and 2 to the repairman. I then went and bought 5 more apples and ate 1. How many apples did I remain with?\n",
    "\n",
    "Let's think step by step.\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program-Aided Language Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use LangChain for convenience so we will introduce LangChain in Session 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm instance\n",
    "llm = OpenAI(model_name='text-davinci-003', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which is the oldest penguin?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PENGUIN_PROMPT = '''\n",
    "\"\"\"\n",
    "Q: Here is a table where the first line is a header and each subsequent line is a penguin:\n",
    "name, age, height (cm), weight (kg) \n",
    "Louis, 7, 50, 11\n",
    "Bernard, 5, 80, 13\n",
    "Vincent, 9, 60, 11\n",
    "Gwen, 8, 70, 15\n",
    "For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm. \n",
    "We now add a penguin to the table:\n",
    "James, 12, 90, 12\n",
    "How many penguins are less than 8 years old?\n",
    "\"\"\"\n",
    "# Put the penguins into a list.\n",
    "penguins = []\n",
    "penguins.append(('Louis', 7, 50, 11))\n",
    "penguins.append(('Bernard', 5, 80, 13))\n",
    "penguins.append(('Vincent', 9, 60, 11))\n",
    "penguins.append(('Gwen', 8, 70, 15))\n",
    "# Add penguin James.\n",
    "penguins.append(('James', 12, 90, 12))\n",
    "# Find penguins under 8 years old.\n",
    "penguins_under_8_years_old = [penguin for penguin in penguins if penguin[1] < 8]\n",
    "# Count number of penguins under 8.\n",
    "num_penguin_under_8 = len(penguins_under_8_years_old)\n",
    "answer = num_penguin_under_8\n",
    "\"\"\"\n",
    "Q: Here is a table where the first line is a header and each subsequent line is a penguin:\n",
    "name, age, height (cm), weight (kg) \n",
    "Louis, 7, 50, 11\n",
    "Bernard, 5, 80, 13\n",
    "Vincent, 9, 60, 11\n",
    "Gwen, 8, 70, 15\n",
    "For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.\n",
    "Which is the youngest penguin?\n",
    "\"\"\"\n",
    "# Put the penguins into a list.\n",
    "penguins = []\n",
    "penguins.append(('Louis', 7, 50, 11))\n",
    "penguins.append(('Bernard', 5, 80, 13))\n",
    "penguins.append(('Vincent', 9, 60, 11))\n",
    "penguins.append(('Gwen', 8, 70, 15))\n",
    "# Sort the penguins by age.\n",
    "penguins = sorted(penguins, key=lambda x: x[1])\n",
    "# Get the youngest penguin's name.\n",
    "youngest_penguin_name = penguins[0][0]\n",
    "answer = youngest_penguin_name\n",
    "\"\"\"\n",
    "Q: Here is a table where the first line is a header and each subsequent line is a penguin:\n",
    "name, age, height (cm), weight (kg) \n",
    "Louis, 7, 50, 11\n",
    "Bernard, 5, 80, 13\n",
    "Vincent, 9, 60, 11\n",
    "Gwen, 8, 70, 15\n",
    "For example: the age of Louis is 7, the weight of Gwen is 15 kg, the height of Bernard is 80 cm.\n",
    "What is the name of the second penguin sorted by alphabetic order?\n",
    "\"\"\"\n",
    "# Put the penguins into a list.\n",
    "penguins = []\n",
    "penguins.append(('Louis', 7, 50, 11))\n",
    "penguins.append(('Bernard', 5, 80, 13))\n",
    "penguins.append(('Vincent', 9, 60, 11))\n",
    "penguins.append(('Gwen', 8, 70, 15))\n",
    "# Sort penguins by alphabetic order.\n",
    "penguins_alphabetic = sorted(penguins, key=lambda x: x[0])\n",
    "# Get the second penguin sorted by alphabetic order.\n",
    "second_penguin_name = penguins_alphabetic[1][0]\n",
    "answer = second_penguin_name\n",
    "\"\"\"\n",
    "{question}\n",
    "\"\"\"\n",
    "'''.strip() + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Put the penguins into a list.\n",
      "penguins = []\n",
      "penguins.append(('Louis', 7, 50, 11))\n",
      "penguins.append(('Bernard', 5, 80, 13))\n",
      "penguins.append(('Vincent', 9, 60, 11))\n",
      "penguins.append(('Gwen', 8, 70, 15))\n",
      "# Sort the penguins by age.\n",
      "penguins = sorted(penguins, key=lambda x: x[1], reverse=True)\n",
      "# Get the oldest penguin's name.\n",
      "oldest_penguin_name = penguins[0][0]\n",
      "answer = oldest_penguin_name\n"
     ]
    }
   ],
   "source": [
    "llm_out = llm(PENGUIN_PROMPT.format(question=question))\n",
    "print(llm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vincent\n"
     ]
    }
   ],
   "source": [
    "exec(llm_out)\n",
    "print(answer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more complex tasks that requires grounding the LM on the latest information, a framework like ReAct can help."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the limitation of the standalone LLM, let's look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "Olivia Wilde's boyfriend is actor Jason Sudeikis. His current age is 44, so raised to the 0.23 power, his age would be approximately 1.8693737."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\"\"\"\n",
    "\n",
    "response = get_completion(params, prompt)\n",
    "IPython.display.Markdown(response.choices[0].text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLMs on their own are unreliable for knowledge-intensive tasks that require up-to-date information. Let's now look at an example with ReAct using LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)\n",
    "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out who Olivia Wilde's boyfriend is and then calculate his age raised to the 0.23 power.\n",
      "Action: Search\n",
      "Action Input: \"Olivia Wilde boyfriend\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mSudeikis and Wilde's relationship ended in November 2020. Wilde was publicly served with court documents regarding child custody while she was presenting Don't Worry Darling at CinemaCon 2022. In January 2021, Wilde began dating singer Harry Styles after meeting during the filming of Don't Worry Darling.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to find out Harry Styles' age.\n",
      "Action: Search\n",
      "Action Input: \"Harry Styles age\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m29 years\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I need to calculate 29 raised to the 0.23 power.\n",
      "Action: Calculator\n",
      "Action Input: 29^0.23\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mAnswer: 2.169459462491557\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: Harry Styles is Olivia Wilde's boyfriend and his current age raised to the 0.23 power is 2.169459462491557.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Harry Styles is Olivia Wilde's boyfriend and his current age raised to the 0.23 power is 2.169459462491557.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the agent\n",
    "agent.run(\"Who is Olivia Wilde's boyfriend? What is his current age raised to the 0.23 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
